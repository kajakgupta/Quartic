{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "#import xgboost as xgb\n",
    "#import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score\n",
    "import datetime\n",
    "\n",
    "data_train = pd.read_csv(\"data_train.csv\")\n",
    "data_test = pd.read_csv(\"data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 0\n",
      "num1 0\n",
      "num2 0\n",
      "num3 0\n",
      "num4 0\n",
      "num5 0\n",
      "num6 0\n",
      "num7 0\n",
      "num8 0\n",
      "num9 0\n",
      "num10 0\n",
      "num11 0\n",
      "num12 0\n",
      "num13 0\n",
      "num14 0\n",
      "num15 0\n",
      "num16 0\n",
      "num17 0\n",
      "num18 107909\n",
      "num19 5\n",
      "num20 1\n",
      "num21 0\n",
      "num22 42667\n",
      "num23 0\n",
      "der1 0\n",
      "der2 0\n",
      "der3 0\n",
      "der4 0\n",
      "der5 0\n",
      "der6 0\n",
      "der7 0\n",
      "der8 0\n",
      "der9 0\n",
      "der10 0\n",
      "der11 0\n",
      "der12 0\n",
      "der13 0\n",
      "der14 0\n",
      "der15 0\n",
      "der16 0\n",
      "der17 0\n",
      "der18 0\n",
      "der19 0\n",
      "cat1 217\n",
      "cat2 83\n",
      "cat3 5814\n",
      "cat4 107\n",
      "cat5 5\n",
      "cat6 411792\n",
      "cat7 0\n",
      "cat8 266928\n",
      "cat9 0\n",
      "cat10 11503\n",
      "cat11 0\n",
      "cat12 570\n",
      "cat13 0\n",
      "cat14 0\n",
      "target 0\n"
     ]
    }
   ],
   "source": [
    "# for column in data_train.columns:\n",
    "# Cheking the number of missing values\n",
    "# if missing values is less than 5% we can remove it. \n",
    "for column in data_train.columns:\n",
    "    print(column , (data_train[column].isnull()).sum())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 0\n",
      "num1 0\n",
      "num2 0\n",
      "num3 0\n",
      "num4 0\n",
      "num5 0\n",
      "num6 0\n",
      "num7 0\n",
      "num8 0\n",
      "num9 0\n",
      "num10 0\n",
      "num11 0\n",
      "num12 0\n",
      "num13 0\n",
      "num14 0\n",
      "num15 0\n",
      "num16 0\n",
      "num17 0\n",
      "num18 0\n",
      "num19 0\n",
      "num20 0\n",
      "num21 0\n",
      "num22 0\n",
      "num23 0\n",
      "der1 0\n",
      "der2 0\n",
      "der3 0\n",
      "der4 0\n",
      "der5 0\n",
      "der6 0\n",
      "der7 0\n",
      "der8 0\n",
      "der9 0\n",
      "der10 0\n",
      "der11 0\n",
      "der12 0\n",
      "der13 0\n",
      "der14 0\n",
      "der15 0\n",
      "der16 0\n",
      "der17 0\n",
      "der18 0\n",
      "der19 0\n",
      "cat1 0\n",
      "cat2 0\n",
      "cat3 0\n",
      "cat4 0\n",
      "cat5 0\n",
      "cat6 0\n",
      "cat7 0\n",
      "cat8 0\n",
      "cat9 0\n",
      "cat10 0\n",
      "cat11 0\n",
      "cat12 0\n",
      "cat13 0\n",
      "cat14 0\n",
      "target 0\n"
     ]
    }
   ],
   "source": [
    "# Since the percentage of missing value is high we will treat it.\n",
    "# we cannot use mean filling as the data are missing in the adjusent cell. Also we have empty first and last cell.\n",
    "# Therefore the missing data will not be treated only by using bfill, we will be using ffill as well. \n",
    "data1 = data_train.fillna(method = 'bfill')\n",
    "#data_tst = data_test.fillna(method = 'bfill')     \n",
    "data2 = data1.fillna(method = 'ffill')\n",
    "#data2_tst1 = data_tst.fillna(method = 'ffill')\n",
    "\n",
    "# cheking for any further missing value.\n",
    "for column in data_train.columns:\n",
    "    print(column , (data2[column].isnull()).sum())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 574284\n",
      "target 21716\n"
     ]
    }
   ],
   "source": [
    "# Target data\n",
    "y = data2.target\n",
    "# Label data\n",
    "X = data2.iloc[:,:-1]\n",
    "\n",
    "# cheking the output to determine the presence of minority and majority class.\n",
    "print('target' , (data_train['target']==0).sum())   \n",
    "print('target' , (data_train['target']==1).sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE time: 0:00:07.512360\n"
     ]
    }
   ],
   "source": [
    "# Output shows imbalanced classes, trainig the model will be biased on majority class.\n",
    "# To avoid the same, we are using SMOTE (Synthetic Minority Over-sampling Technique) to increase the minory sample.\n",
    "start_time = datetime.datetime.now()\n",
    "smote_res = SMOTE()\n",
    "Xtrain_res, ytrain_res = smote_res.fit_sample(X, y)\n",
    "end_time = datetime.datetime.now()\n",
    "print('SMOTE time:', end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data to train the model\n",
    "# In the below snippit we are splitting the data (train:test) into 80:20 ration by giving test_size=.2.\n",
    "# Since the splitting of data is done randomly. Random State can be changed on the ground of getting best result.\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xtrain_res, ytrain_res, test_size=.2, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 0:01:11.533687\n",
      "predict time: 0:00:00.694568\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98    115104\n",
      "          1       1.00      0.96      0.98    114610\n",
      "\n",
      "avg / total       0.98      0.98      0.98    229714\n",
      "\n",
      "0.9807717422534108\n",
      "[[115098      6]\n",
      " [  4411 110199]]\n",
      "testing time: 0:00:00.300815\n"
     ]
    }
   ],
   "source": [
    "# randomforest we cannot visualise\n",
    "# we can visualise decision tree\n",
    "start_time = datetime.datetime.now()\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "end_time = datetime.datetime.now()\n",
    "print('training time:', end_time - start_time)\n",
    "start_time_pred = datetime.datetime.now()\n",
    "y_pred = clf.predict(X_test)\n",
    "end_time_pred = datetime.datetime.now()\n",
    "print('predict time:', end_time_pred - start_time_pred)\n",
    "data_test.loc[:, 'Target'] = y_pred\n",
    "data_test.to_csv(\"Final_Predict.csv\")\n",
    "start_time_test = datetime.datetime.now()\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "end_time_test = datetime.datetime.now()\n",
    "print('testing time:', end_time_test - start_time_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
